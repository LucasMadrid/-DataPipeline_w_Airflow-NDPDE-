# Data Pipeline with Apache Airflow
Hi there, as an engineer at the startup Sparkify I was asked to create a data pipeline to build the data model (Dimensional Modelling) for our Analytics team. They need 
a Data Pipeline to *consume the data from a S3 bucket (It can be a data lake as well), load the data into staging tabla and process the data through SQL statements triggered
by Task in apache airflow to finally load the transformed data into the dimensional modelling*  with data from the app and the logs of the users to get insight of what music/artist/song
are they listening.

### Techonologies Involved:
- Programming Language:
  - Python.
- Data Orchestration:
  - Apache Airflow.
- Cloud Computing:
  - AWS:
    - S3 Bucket.
    - Redshift (Cloud Data Warehouse).
    
    
  
